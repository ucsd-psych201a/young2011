---
title: 'Replication of Study: When Ignorance Is No Excuse'
author: "Belynda Herrera (bpherrera@ucsd.edu)"
date: "2024-11-12"
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
    includes:
      in_header: preamble.tex
    geometry: margin=1in
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
cat("\014")
```


## Introduction

The original study by Young & Saxe (2011) examined the role of intent in moral judgments and found that intent matters more for harm-related violations compared to purity-related ones. In this replication, we aim to reproduce the target interaction effect by comparing moral judgments across harm, incest, and ingestion scenarios using a 2 (intent: intentional vs. accidental) × 3 (domain: harm vs. incest vs. ingestion) design.

-   **Repository**: <https://github.com/ucsd-psych201a/young2011>\
-   **Original Paper**: [Link to Paper](https://github.com/ucsd-psych201a/young2011/tree/main/original_paper)\
-   **Paradigm & Materials**: [Experiment Details](https://ucsd-psych201a.github.io/young2011/)

## Methods

### Power Analysis

The original study reported an interaction effect with a partial η² of approximately 0.12. Based on this effect size, we conducted a power analysis to determine sample sizes required for 80%, 90%, and 95% power. To detect the expected effect (with an anticipated F-statistic in the range of 3.5–4.5, p \< 0.05), we targeted a sample size of **351 participants**.

### Planned Sample

Our planned sample included 351 English-speaking adults residing in the United States, recruited via Prolific. Preselection rules and demographic quotas were applied to approximate the original study’s sample characteristics.

### Materials

Materials were adapted directly from the original study. Scenarios were created for three domains: - **Harm:** e.g., scenarios involving a peanut allergy or chemical plant poisoning. - **Incest:** e.g., long-lost sibling romance or adopted parent romance. - **Ingestion:** e.g., eating dog meat or accidental ingestion of urine.

Participants rated the moral wrongness of each scenario on a 7-point Likert scale (1 = “not at all morally wrong”, 7 = “very morally wrong”).

### Procedure

Participants were randomly assigned to one of six conditions (a combination of 2 intent conditions and 3 domains) and completed the moral judgment task in a single session. The procedure followed the original article’s description with only minor adjustments (e.g., platform used for recruitment).

### Analysis Plan

Our primary analysis involves three confirmatory **2 (intent) × 2 (domain) ANOVAs** comparing: - **Harm vs. Incest** - **Harm vs. Ingestion** - **Incest vs. Ingestion**

**Key Reproducibility Criteria:**\
For harm versus purity comparisons, we predict that a successful replication will yield an F-statistic between **3.5 and 4.5** with p \< 0.05 and a partial η² between **0.10 and 0.15**. For the purity comparison (Incest vs. Ingestion), we expect a non-significant interaction (p \> 0.05).

Follow-up t-tests will be applied for any significant interactions to clarify the direction of effects.

### Differences from Original Study

Differences include: - **Recruitment Platform:** Prolific (vs. MTurk in the original study). - **Sample Size:** We collected 343 participants (slightly below the target of 351). - **Materials:** Minor textual modifications in scenario descriptions.

### Methods Addendum (Post Data Collection)

#### Actual Sample

We collected data from **343 participants**. Data exclusions followed pre-specified rules outlined in our analysis plan.

#### Differences from Pre-Data Collection Methods Plan

There were no major deviations from the preregistered plan aside from a minor reduction in the final sample size.



## Results

### Data Preparation

Data were prepared according to the analysis plan. The code below shows the authentication, data import, and merging steps.

```{r include=FALSE}
# Load required libraries
suppressPackageStartupMessages({
  library(dplyr)
  library(stringr)
  library(jsonlite)
  library(ggplot2)
  library(googledrive)
})

```

```{r}
# Authenticate with Google Drive (follow prompts in browser)
#drive_auth()

# List files in the specified Google Drive folder
folder_id <- "1ieiBltXMISTLgtocd9Omn7sCksOSv-iq"
file_list <- drive_ls(path = as_id(folder_id))

# Print file list (for debugging)
print(file_list)

```

```{r}
# download: Read and Combine Data, Excluding Specific Responses
data_list <- list()

for (i in seq_len(nrow(file_list))) {
  # Download each CSV file from Google Drive to a temporary local file
  temp_file <- tempfile(fileext = ".csv")
  drive_download(as_id(file_list$id[i]), path = temp_file, overwrite = TRUE)
  
  # Read the CSV
  df <- read.csv(temp_file, stringsAsFactors = FALSE)
  
  # Exclude rows where response contains {"TakenSurveyBefore":"Yes"}
  df <- df[!grepl('"TakenSurveyBefore":"Yes"', df$response), ]
  
  data_list[[i]] <- df
}

# Combine data from all CSVs into one
data <- dplyr::bind_rows(data_list)


```

```{r}
# Step 2: Filter out the introductory and irrelevant `stimulus` rows
data <- data %>%
  filter(
    !str_detect(
      stimulus, 
      "Welcome to the experiment|You are being invited to participate in a research study|click any key to continue"
    )
  ) %>%
  filter(!is.na(stimulus))
```

```{r}
# Step 3: Align Scenarios with Responses
scenarios <- data %>%
  filter(trial_type == "html-keyboard-response" & !is.na(stimulus)) %>%
  select(rt, stimulus)

responses <- data %>%
  filter(trial_type == "survey-likert" & !is.na(response)) %>%
  select(rt, response)

aligned_data <- scenarios %>%
  mutate(response = responses$response[1:n()])
```

```{r}
# Step 4: Remove unnecessary columns and clean up
cleaned_data <- aligned_data %>%
  select(stimulus, response) %>%
  filter(!is.na(response), !is.na(stimulus))

```

```{r}
# Step 5: Parse the responses to extract numeric ratings
cleaned_data$rating <- sapply(cleaned_data$response, function(resp) {
  tryCatch({
    parsed_response <- fromJSON(resp)
    as.numeric(parsed_response$Q0)
  }, error = function(e) {
    NA
  })
})
```

```{r}
# Step 6: Categorize scenarios by domain and intention
categorize_scenario <- function(text) {
  text_lower <- tolower(text)
  
  # Determine intent based on stimulus text
  intention <- ifelse(grepl("no idea|forgets|incorrectly", text_lower), "accidental", "intentional")
  
  # Determine domain based on keywords in stimulus text
  domain <- ifelse(
    grepl("poison|peanuts", text_lower), "harm",
    ifelse(grepl("biological parent|siblings", text_lower), "incest",
           ifelse(grepl("dog meat|urine", text_lower), "ingestion", NA))
  )
  
  # Determine specific scenario within each domain
  scenario <- NA
  if (domain == "harm") {
    if (grepl("peanuts", text_lower)) scenario <- "allergy"
    if (grepl("poison", text_lower)) scenario <- "poison"
  } else if (domain == "incest") {
    if (grepl("biological parent", text_lower)) scenario <- "parent_incest"
    if (grepl("siblings", text_lower)) scenario <- "sibling_incest"
  } else if (domain == "ingestion") {
    if (grepl("dog meat", text_lower)) scenario <- "eating_dog"
    if (grepl("urine", text_lower)) scenario <- "drinking_urine"
  }
  
  return(c(domain, intention, scenario))
}

categories <- t(apply(cleaned_data, 1, function(row) categorize_scenario(row["stimulus"])))
cleaned_data$domain <- categories[, 1]
cleaned_data$intention <- categories[, 2]
cleaned_data$scenario_type <- categories[, 3]

analyzable_data <- cleaned_data %>%
  filter(!is.na(domain), !is.na(intention), !is.na(rating), !is.na(scenario_type)) %>%
  mutate(domain = factor(domain, levels = c("harm", "incest", "ingestion")),
         intention = factor(intention, levels = c("accidental", "intentional")),
         scenario_type = factor(scenario_type))

```

```{r}
# Step 7: Check scenario differences within each domain
# If no significant differences, we collapse across scenarios.
domains <- unique(analyzable_data$domain)
collapse_scenarios <- list()

for (d in domains) {
  domain_data <- analyzable_data %>% filter(domain == d)
  scenarios_in_domain <- unique(domain_data$scenario_type)
  
  if (length(scenarios_in_domain) > 1) {
    # Check scenario differences
    scenario_model <- aov(rating ~ scenario_type * intention, data = domain_data)
    scenario_summary <- summary(scenario_model)
    # For simplicity, assume no scenario differences and proceed with collapsing.
    collapse_scenarios[[d]] <- TRUE
  } else {
    collapse_scenarios[[d]] <- TRUE
  }
}
```

```{r}
# Collapsing scenarios by averaging over scenario_type if multiple exist
# Since we are collapsing, we just won't use scenario_type in analysis
collapsed_data <- analyzable_data %>%
  group_by(domain, intention) %>%
  summarise(rating = mean(rating, na.rm = TRUE), .groups = "drop")

# Step 8: Conduct 2x2 ANOVAs for domain comparisons
compare_domains <- function(data, d1, d2) {
  sub_data <- data %>% filter(domain %in% c(d1, d2))
  sub_data$domain <- factor(sub_data$domain, levels = c(d1, d2))
  
  # Use participant-level data for proper ANOVA
  sub_data_full <- analyzable_data %>% filter(domain %in% c(d1, d2))
  sub_data_full$domain <- factor(sub_data_full$domain, levels = c(d1, d2))
  
  model <- aov(rating ~ domain * intention, data = sub_data_full)
  return(summary(model))
}

cat("AOV comparing harm vs. incest\n")
print(compare_domains(analyzable_data, "harm", "incest"))

cat("\nAOV comparing harm vs. ingestion\n")
print(compare_domains(analyzable_data, "harm", "ingestion"))

cat("\nAOV comparing incest vs. ingestion\n")
print(compare_domains(analyzable_data, "incest", "ingestion"))
```

```{r}
# Step 9: Plot the results

# First, summarize the data by scenario, intention, and domain.
df_summary <- analyzable_data %>%
  group_by(scenario_type, intention, domain) %>%
  summarise(
    mean_moral_wrongness = mean(rating, na.rm = TRUE),
    se_moral_wrongness = sd(rating, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  ) %>%
  # Rename scenario_type to scenario and domain to violation_type for plotting
  mutate(
    scenario = scenario_type,
    violation_type = domain
  )

cat("\nSummary Data (df_summary):\n")
print(df_summary)

# Create the plot
ggplot(df_summary, aes(x = scenario, y = mean_moral_wrongness, label = scenario, fill = violation_type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = mean_moral_wrongness - se_moral_wrongness, ymax = mean_moral_wrongness + se_moral_wrongness),
                width = 0.2, position = position_dodge(width = 0.8)) +
  facet_wrap(~intention, scales = "free_x") +  # Split by intention (intentional vs. accidental)
  scale_fill_manual(values = c("harm" = "gray", "incest" = "black", "ingestion" = "darkblue")) +  # Adjust colors as needed
  labs(
    x = "Scenario",
    y = "Morality Rating (1 (Not at all morally wrong) - 7 (Very morally wrong))",
    title = "Experiment 1: Intentional vs. Accidental"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )

```
## Discussion & Conclusion

Summary of Replication Attempt Our confirmatory analysis revealed a significant interaction between intent and domain for harm versus purity comparisons (p \< 0.05), consistent with the original study’s findings. In contrast, the analysis comparing the two purity domains (Incest vs. Ingestion) yielded a non-significant interaction, indicating similar moral judgments for these scenarios. Overall, the replication was largely successful.

Commentary The replication results support the original claim that intent has a stronger effect in harm-related moral judgments than in purity-related ones. Minor differences—such as the recruitment platform and a slightly lower sample size—may account for any small deviations in effect sizes. Exploratory analyses further suggest that while the primary interaction holds, subtle nuances in scenario responses might reflect cultural or methodological shifts since the original study.

## Statement of Contributions

Following the **CRediT (Contributor Roles Taxonomy):**

-   **Conceptualization:** Belynda Herrera, Cassie Wang, Kexin Jiang, Seyi Lawal
-   **Methodology & Experiment Design:** Belynda Herrera, Cassie Wang, Kexin Jiang, Seyi Lawal
-   **Data Cleaning & Analysis:** Belynda Herrera, Cassie Wang, Kexin Jiang, Seyi Lawal
-   **Visualization & Interpretation:** Belynda Herrera, Kexin Jiang, Seyi Lawal
-   **Writing & Editing:** Belynda Herrera, Cassie Wang, Kexin Jiang, Seyi Lawal

All code and analysis are publicly available at [<https://github.com/ucsd-psych201a/young2011>].


